# AgentFlow CLI Examples

This directory contains comprehensive examples for using AgentFlow CLI with different model types, particularly focusing on StepFun's specialized capabilities.

## Prerequisites

Before running these examples, ensure you have:

1. **Built the CLI**: 
   ```bash
   cargo build --package agentflow-cli
   ```

2. **Set up API keys** (add to your environment or `.env` file):
   ```bash
   export STEP_API_KEY="your-stepfun-api-key-here"
   export OPENAI_API_KEY="your-openai-api-key-here"  # Optional
   export ANTHROPIC_API_KEY="your-anthropic-api-key"  # Optional
   ```

3. **Initialize AgentFlow configuration**:
   ```bash
   agentflow config init
   ```

## Example Categories

### ğŸ“ Text Generation Models
- [Text Models](#text-models) - Basic text completion with various StepFun models
- [Long Context](#long-context) - Working with extended context windows
- [Streaming](#streaming-text) - Real-time text generation

### ğŸ–¼ï¸ Vision Models  
- [Image Understanding](#image-understanding) - Analyze and describe images
- [Chart Analysis](#chart-analysis) - Interpret graphs and diagrams
- [Multimodal](#multimodal-analysis) - Combined text and image processing

### ğŸ¨ Image Generation
- [Text-to-Image](#text-to-image) - Generate images from text descriptions
- [Style Transfer](#style-transfer) - Apply artistic styles to generated images
- [Image Editing](#image-editing) - Modify existing images with text instructions

### ğŸ”Š Audio Processing
- [Text-to-Speech](#text-to-speech) - Convert text to natural speech
- [Speech Recognition](#speech-recognition) - Transcribe audio to text
- [Voice Cloning](#voice-cloning) - Create custom voice models

## Quick Start Examples

### Text Models

#### Basic Text Generation
```bash
# Quick response with step-2-mini (fast model)
agentflow llm prompt "è§£é‡Šä¸ºä»€ä¹ˆå¤©ç©ºæ˜¯è“è‰²çš„ï¼Ÿç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€å›ç­”ã€‚" \
  --model step-2-mini \
  --temperature 0.5 \
  --max-tokens 300

# Code generation with step-2-16k
agentflow llm prompt "ç”¨Pythonå®ç°ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•ï¼Œè¦æ±‚åŒ…å«è¯¦ç»†æ³¨é‡Šå’Œæµ‹è¯•ç”¨ä¾‹ã€‚" \
  --model step-2-16k \
  --temperature 0.7 \
  --max-tokens 1000 \
  --output quicksort.py
```

#### Long Context Processing
```bash
# Process large documents with step-1-256k
agentflow llm prompt "æ ¹æ®æ–‡æ¡£æ€»ç»“äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ä¹‹é—´çš„å…³ç³»" \
  --model step-1-256k \
  --file ai_document.txt \
  --temperature 0.7 \
  --max-tokens 600 \
  --output summary.md
```

#### Streaming Text Generation
```bash
# Real-time text generation with step-1-32k
agentflow llm prompt "è¯¦ç»†è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†ï¼ŒåŒ…æ‹¬é‡å­æ¯”ç‰¹ã€å åŠ æ€ã€çº ç¼ ç°è±¡" \
  --model step-1-32k \
  --stream \
  --temperature 0.8 \
  --max-tokens 800
```

### Image Understanding

#### Basic Image Analysis
```bash
# Analyze image content with step-1o-turbo-vision
agentflow llm prompt "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ™¯è‰²ã€é¢œè‰²ã€æ„å›¾ç­‰è¦ç´ ã€‚" \
  --model step-1o-turbo-vision \
  --file landscape.jpg \
  --temperature 0.7 \
  --max-tokens 500
```

#### Chart and Data Analysis
```bash
# Interpret charts with step-1v-8k
agentflow llm prompt "åˆ†æè¿™ä¸ªå›¾è¡¨ï¼Œè§£é‡Šå…¶ä¸­çš„æ•°æ®è¶‹åŠ¿ã€åæ ‡è½´å«ä¹‰ï¼Œä»¥åŠå¯èƒ½çš„ç»Ÿè®¡å…³ç³»ã€‚" \
  --model step-1v-8k \
  --file sales_chart.png \
  --temperature 0.6 \
  --max-tokens 600
```

#### Comprehensive Image Analysis
```bash
# Detailed analysis with step-1v-32k
agentflow llm prompt "è¯·ä»ä»¥ä¸‹å‡ ä¸ªè§’åº¦è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼š1)åœºæ™¯å’Œåœ°ç‚¹ç‰¹å¾ 2)å…‰çº¿å’Œè‰²å½©è¿ç”¨ 3)äººæ–‡å’Œç¤¾ä¼šå…ƒç´  4)æ„å›¾å’Œè§†è§‰æ•ˆæœ 5)å¯èƒ½çš„æ‹æ‘„æŠ€å·§" \
  --model step-1v-32k \
  --file photo.jpg \
  --temperature 0.7 \
  --max-tokens 800 \
  --output detailed_analysis.md
```

### Multi-Image Comparison
```bash
# Compare multiple images with step-3
agentflow llm prompt "è¯·åˆ†æè¿™äº›å›¾ç‰‡çš„å†…å®¹å·®å¼‚ï¼Œæ¯”è¾ƒå®ƒä»¬çš„ç‰¹ç‚¹ï¼Œå¹¶è§£é‡Šä¸ºä»€ä¹ˆè¿™ç§å¤šæ ·æ€§åœ¨è§†è§‰å†…å®¹ä¸­å¾ˆé‡è¦ã€‚" \
  --model step-3 \
  --file image1.jpg \
  --file image2.jpg \
  --temperature 0.8 \
  --max-tokens 700
```

## Specialized API Examples

> **Note**: The following examples require workflow execution capabilities, which are implemented in Phase 2. For now, they are provided as templates for future CLI integration.

### Text-to-Image Generation
```bash
# Basic image generation (Future CLI integration)
agentflow generate image \
  --model step-2x-large \
  --prompt "æœªæ¥ç§‘æŠ€åŸå¸‚å¤œæ™¯ï¼Œéœ“è™¹ç¯é—ªçƒï¼Œé«˜æ¥¼å¤§å¦æ—ç«‹ï¼Œèµ›åšæœ‹å…‹é£æ ¼ï¼Œ4Kè¶…é«˜æ¸…" \
  --size 1024x1024 \
  --format b64_json \
  --output cyberpunk_city.png

# Quick generation with step-1x-medium
agentflow generate image \
  --model step-1x-medium \
  --prompt "å¯çˆ±çš„å°çŒ«å’ªåœ¨èŠ±å›­ä¸­ç©è€ï¼Œé˜³å…‰æ˜åªšï¼Œè‰²å½©é²œè‰³ï¼Œå¡é€šé£æ ¼" \
  --size 768x768 \
  --steps 20 \
  --cfg-scale 7.0 \
  --output cute_cat.png
```

### Text-to-Speech
```bash
# Basic TTS with step-tts-vivid (Future CLI integration)
agentflow generate speech \
  --model step-tts-vivid \
  --text "æ™ºèƒ½é˜¶è·ƒï¼Œåå€æ¯ä¸€ä¸ªäººçš„å¯èƒ½ã€‚äººå·¥æ™ºèƒ½åŠ©åŠ›æœªæ¥å‘å±•ã€‚" \
  --voice cixingnansheng \
  --format mp3 \
  --speed 1.0 \
  --output welcome_message.mp3

# Fast synthesis with step-tts-mini
agentflow generate speech \
  --model step-tts-mini \
  --text "ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨AgentFlow CLIå·¥å…·ï¼" \
  --voice default \
  --format wav \
  --speed 1.2 \
  --output greeting.wav
```

### Speech Recognition
```bash
# Transcribe audio with step-asr (Future CLI integration)
agentflow transcribe audio \
  --model step-asr \
  --file meeting_recording.wav \
  --format json \
  --language zh \
  --output transcript.json

# Simple text transcription
agentflow transcribe audio \
  --model step-asr \
  --file voice_memo.mp3 \
  --format text \
  --output memo_text.txt
```

## Workflow Examples

### Complete Multimodal Pipeline
```yaml
# multimodal_analysis.yml - Comprehensive multimodal workflow
name: "Multimodal Content Analysis"
description: "Analyze images and generate comprehensive reports"

inputs:
  image_path:
    type: "string"
    required: true
  analysis_depth:
    type: "string"
    default: "detailed"

workflow:
  type: "sequential"
  nodes:
    - name: "analyze_image"
      type: "llm"
      config:
        model: "step-1v-32k"
        prompt: |
          è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼š{{ inputs.image_path }}
          
          åˆ†ææ·±åº¦ï¼š{{ inputs.analysis_depth }}
          
          è¯·ä»æŠ€æœ¯å’Œè‰ºæœ¯è§’åº¦åˆ†æè¿™å¼ å›¾ç‰‡ã€‚
        file: "{{ inputs.image_path }}"
        temperature: 0.7
        max_tokens: 800
      outputs:
        visual_analysis: "$.response"
    
    - name: "generate_summary"
      type: "template"
      depends_on: ["analyze_image"]
      config:
        template: |
          # å›¾ç‰‡åˆ†ææŠ¥å‘Š
          
          **å›¾ç‰‡è·¯å¾„**: {{ inputs.image_path }}
          **åˆ†ææ—¶é—´**: {{ now() }}
          **åˆ†ææ·±åº¦**: {{ inputs.analysis_depth }}
          
          ## è§†è§‰åˆ†æç»“æœ
          
          {{ outputs.analyze_image.visual_analysis }}
          
          ---
          *æŠ¥å‘Šç”± AgentFlow CLI ç”Ÿæˆ*

outputs:
  report:
    source: "{{ outputs.generate_summary.rendered }}"
    format: "markdown"
    file: "analysis_report.md"
```

Usage:
```bash
agentflow run multimodal_analysis.yml \
  --input image_path=./photos/landscape.jpg \
  --input analysis_depth=comprehensive
```

### Content Generation Pipeline
```yaml
# content_pipeline.yml - Multi-step content creation
name: "AI Content Generation Pipeline"
description: "Generate text, images, and audio from a single topic"

inputs:
  topic:
    type: "string"
    required: true
  content_style:
    type: "string"
    default: "professional"

workflow:
  type: "sequential"
  nodes:
    - name: "research_content"
      type: "llm"
      config:
        model: "step-2-16k"
        prompt: |
          ç ”ç©¶ä¸»é¢˜ï¼š{{ inputs.topic }}
          é£æ ¼ï¼š{{ inputs.content_style }}
          
          è¯·æä¾›ï¼š
          1. æ ¸å¿ƒæ¦‚å¿µå’Œå®šä¹‰
          2. æœ€æ–°å‘å±•è¶‹åŠ¿
          3. å®é™…åº”ç”¨æ¡ˆä¾‹
          4. æœªæ¥å‘å±•æ–¹å‘
        temperature: 0.3
        max_tokens: 1500
    
    - name: "generate_article"
      type: "llm"  
      depends_on: ["research_content"]
      config:
        model: "step-1-32k"
        prompt: |
          åŸºäºä»¥ä¸‹ç ”ç©¶å†…å®¹ï¼Œå†™ä¸€ç¯‡å…³äº"{{ inputs.topic }}"çš„æ–‡ç« ï¼š
          
          {{ outputs.research_content.response }}
          
          è¦æ±‚ï¼š
          - é£æ ¼ï¼š{{ inputs.content_style }}
          - ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘æ€§å¼º
          - åŒ…å«å®ä¾‹å’Œæ•°æ®æ”¯æ’‘
          - å­—æ•°çº¦2000å­—
        temperature: 0.7
        max_tokens: 2500

outputs:
  research:
    source: "{{ outputs.research_content.response }}"
    format: "markdown"
    file: "{{ inputs.topic }}_research.md"
  
  article:
    source: "{{ outputs.generate_article.response }}"
    format: "markdown" 
    file: "{{ inputs.topic }}_article.md"
```

Usage:
```bash
agentflow run content_pipeline.yml \
  --input topic="åŒºå—é“¾æŠ€æœ¯åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨" \
  --input content_style="å­¦æœ¯æ€§"
```

## File Format Examples

### Working with Different Input Types

#### Text Files
```bash
# Process code files
agentflow llm prompt "ä»£ç å®¡æŸ¥ï¼šåˆ†æè¿™æ®µä»£ç çš„æ€§èƒ½å’Œå®‰å…¨æ€§" \
  --model step-2-16k \
  --file app.py \
  --output code_review.md

# Analyze documents
agentflow llm prompt "æ€»ç»“è¿™ä»½æŠ€æœ¯æ–‡æ¡£çš„è¦ç‚¹" \
  --model step-1-32k \
  --file technical_spec.md \
  --max-tokens 1000
```

#### Image Files
```bash
# Multiple image formats supported
agentflow llm prompt "æ¯”è¾ƒè¿™äº›äº§å“å›¾ç‰‡çš„è®¾è®¡ç‰¹ç‚¹" \
  --model step-3 \
  --file product1.jpg \
  --file product2.png \
  --file product3.webp \
  --temperature 0.8
```

#### Audio Files (Future)
```bash
# Transcribe different audio formats
agentflow transcribe audio --file interview.mp3
agentflow transcribe audio --file lecture.wav  
agentflow transcribe audio --file podcast.m4a
```

## Performance Tips

### Model Selection Guide

| Task Type | Recommended Model | Speed | Quality | Context |
|-----------|------------------|-------|---------|---------|
| Quick Q&A | step-2-mini | âš¡âš¡âš¡ | â­â­â­ | 8K |
| Code Generation | step-2-16k | âš¡âš¡ | â­â­â­â­ | 16K |
| Long Documents | step-1-256k | âš¡ | â­â­â­â­ | 256K |
| Streaming Chat | step-1-32k | âš¡âš¡ | â­â­â­â­ | 32K |
| Image Analysis | step-1o-turbo-vision | âš¡âš¡ | â­â­â­â­ | Vision |
| Chart Analysis | step-1v-8k | âš¡âš¡ | â­â­â­â­ | Vision |
| Detailed Vision | step-1v-32k | âš¡ | â­â­â­â­â­ | Vision |
| Multimodal | step-3 | âš¡ | â­â­â­â­â­ | Advanced |

### Optimization Tips

1. **Choose appropriate models**: Use faster models for simple tasks
2. **Set reasonable token limits**: Avoid unnecessary costs
3. **Use streaming**: For long responses that need immediate feedback
4. **Batch similar requests**: Group related tasks in workflows
5. **Cache results**: Save outputs for reuse in complex pipelines

## Troubleshooting

### Common Issues

1. **API Key not found**: Ensure `STEP_API_KEY` is set in environment
2. **Model not available**: Check available models with `agentflow llm models`
3. **File not found**: Use absolute paths or ensure files exist
4. **Token limit exceeded**: Reduce `max-tokens` or split content
5. **Rate limiting**: Add delays between requests or use smaller batches

### Debug Mode
```bash
# Enable verbose logging
agentflow llm prompt "test" --model step-2-mini --verbose --log-level debug
```

## Contributing

To add new examples:

1. Create a new example file in the appropriate category directory
2. Include both CLI commands and workflow YAML examples  
3. Add validation and expected outputs
4. Update this README with the new example
5. Test with actual API calls before submitting

---

*For more information, see the [AgentFlow CLI README](../README.md) and the [main AgentFlow documentation](../../README.md).*