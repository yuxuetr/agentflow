# Chat Bot - Conversational AI Workflow
name: "Interactive Chat Bot"
version: "1.0.0"
description: "A conversational AI chatbot with message history using OpenAI models"
author: "AgentFlow Team"

metadata:
  created: "2024-01-15T00:00:00Z"
  tags: ["openai", "chat", "conversation", "interactive"]
  category: "interactive"

config:
  timeout: "10m"
  max_retries: 3
  output_format: "text"
  log_level: "info"

inputs:
  user_message:
    type: "string"
    required: true
    description: "The user's message to the chatbot"
    example: "Hello, can you help me understand quantum physics?"
  
  conversation_history:
    type: "array"
    required: false
    default: []
    description: "Previous conversation messages"
  
  model:
    type: "string"
    required: false
    default: "gpt-4o"
    enum: ["gpt-4o", "gpt-4", "gpt-3.5-turbo", "gpt-4o-mini"]
    description: "OpenAI model to use for chat"

  temperature:
    type: "number"
    required: false
    default: 0.7
    description: "Temperature for response generation (0.0-1.0)"

  max_history_length:
    type: "number"
    required: false
    default: 20
    description: "Maximum number of messages to keep in history"

environment:
  OPENAI_API_KEY: "required"

workflow:
  type: "sequential"
  nodes:
    - name: "prepare_conversation"
      type: "template"
      description: "Prepare conversation context with history"
      config:
        template: |
          {% set messages = inputs.conversation_history %}
          {% set _ = messages.append({"role": "user", "content": inputs.user_message}) %}
          {% if messages|length > inputs.max_history_length %}
            {% set messages = messages[-inputs.max_history_length:] %}
          {% endif %}
          {{ messages | tojson }}
      outputs:
        messages: "$.rendered"

    - name: "generate_response"
      type: "llm"
      description: "Generate AI response to user message"
      config:
        model: "{{ inputs.model }}"
        messages: "{{ prepare_conversation.messages | fromjson }}"
        temperature: "{{ inputs.temperature }}"
        max_tokens: 1000
        system: "You are a helpful, friendly, and knowledgeable AI assistant. Engage in natural conversation and provide helpful responses."
        timeout: "3m"
      outputs:
        response: "$.response"

    - name: "update_history"
      type: "template"
      description: "Update conversation history with new response"
      config:
        template: |
          {% set messages = prepare_conversation.messages | fromjson %}
          {% set _ = messages.append({"role": "assistant", "content": generate_response.response}) %}
          {{ messages | tojson }}
      outputs:
        updated_history: "$.rendered"

outputs:
  assistant_response:
    source: "{{ generate_response.response }}"
    format: "text"
    file: "output/assistant_response.txt"
  
  conversation_history:
    source: "{{ update_history.updated_history | fromjson }}"
    format: "json"
    file: "output/conversation_history.json"
  
  execution_report:
    source: "$"
    format: "json"
    file: "output/execution_report.json"
    include:
      - execution_time
      - model_used
      - message_count
      - conversation_length