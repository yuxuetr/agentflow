# AgentFlow Recipe Finder Workflow - Simplified Configuration
# Based on PocketFlow cookbook/pocketflow-async-basic example
name: "Simple Recipe Finder"
description: "Find and suggest a recipe based on user ingredient"

# Input parameters for the workflow
inputs:
  ingredient:
    type: string
    required: true
    description: "Main ingredient to find recipes for"
    default: "chicken"

# Sequential workflow - simplified version
workflow:
  # Step 1: Fetch and analyze recipes
  - name: fetch_and_suggest
    type: llm
    model: "step-2-mini"
    prompt: |
      You are a helpful chef assistant. I need you to:
      
      1. First, imagine you're calling a recipe API for "{{ ingredient }}" recipes
      2. Generate 5 different recipe ideas using {{ ingredient }}
      3. Choose the most appealing one
      4. Return your recommendation
      
      Format your response as:
      "I found several {{ ingredient }} recipes! I recommend: [RECIPE NAME]
      
      Other options included: [list other 4 recipes]"
      
      Make it conversational and helpful.
    system: "You are a helpful chef assistant who finds and recommends recipes based on ingredients."
    temperature: 0.8
    max_tokens: 300
    outputs:
      recipe_recommendation: response

  # Step 2: Get user feedback simulation
  - name: user_feedback
    type: llm
    model: "step-2-mini"
    prompt: |
      A user received this recipe recommendation:
      
      {{ recipe_recommendation }}
      
      Simulate a realistic user response. The user might:
      - Accept the recommendation enthusiastically
      - Ask for modifications or alternatives
      - Request a different cooking style
      - Have dietary restrictions
      
      Respond as if you're the user, in 1-2 sentences.
    system: "You are simulating a user receiving a recipe recommendation. Respond naturally as a real person would."
    temperature: 0.9
    max_tokens: 100
    outputs:
      user_response: response

  # Step 3: Chef's final response
  - name: chef_response
    type: llm
    model: "step-2-mini"
    prompt: |
      The user said: "{{ user_response }}"
      
      Your original recommendation was: {{ recipe_recommendation }}
      
      As a helpful chef, provide a final response that:
      - Acknowledges their feedback
      - Provides additional help if needed
      - Offers cooking tips or alternatives if requested
      - Maintains a friendly, professional tone
    system: "You are a helpful chef assistant providing follow-up support and cooking advice."
    temperature: 0.7
    max_tokens: 200
    outputs:
      final_response: response

# Final outputs
outputs:
  recommended_recipe:
    from: fetch_and_suggest.response
    description: "The chef's initial recipe recommendation"
  
  user_feedback:
    from: user_feedback.response
    description: "Simulated user feedback on the recommendation"
  
  chef_final_advice:
    from: chef_response.response
    description: "Chef's final response and advice"