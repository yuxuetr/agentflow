# Comprehensive Multi-Modal AgentFlow Workflow Configuration Template
# This template demonstrates advanced workflow patterns with diverse node types,
# conditional branching, loops, and complex shared_state management

name: "Advanced Multi-Modal Content Pipeline"
version: "2.0.0" 
description: "Complex workflow showcasing multi-modal processing, conditional logic, loops, and advanced control structures"
author: "AgentFlow Advanced Team"

metadata:
  created: "2024-01-15T00:00:00Z"
  tags: ["multimodal", "ai", "advanced", "production", "conditional", "loops"]
  category: "production"
  complexity: "advanced"
  estimated_duration: "15-30m"

# Advanced execution configuration
config:
  timeout: "30m"
  max_retries: 3
  output_format: "structured"
  log_level: "info"
  parallel_limit: 4
  batch_size: 2
  enable_observability: true
  enable_checkpoints: true
  checkpoint_interval: "5m"
  error_recovery: "retry_with_backoff"
  resource_limits:
    max_memory: "2GB"
    max_cpu_cores: 4
    max_gpu_memory: "8GB"

# Comprehensive input definitions with validation
inputs:
  # Content inputs
  content_topic:
    type: "string"
    required: true
    description: "Main topic for content generation"
    example: "The future of sustainable technology"
    validation:
      min_length: 10
      max_length: 200
  
  source_documents:
    type: "array"
    items: "string"
    required: false
    description: "URLs or file paths to source documents"
    example: ["./docs/sustainability.pdf", "https://example.com/tech-trends"]
  
  # Media inputs
  reference_images:
    type: "array" 
    items: "file"
    required: false
    description: "Reference images for visual analysis"
    validation:
      file_types: ["jpg", "jpeg", "png", "webp"]
      max_size: "10MB"
      max_count: 5
  
  audio_inputs:
    type: "array"
    items: "file" 
    required: false
    description: "Audio files for transcription and analysis"
    validation:
      file_types: ["mp3", "wav", "m4a", "flac"]
      max_size: "50MB"
      max_duration: "10m"
  
  # Processing parameters
  content_style:
    type: "string"
    required: false
    default: "professional"
    enum: ["academic", "professional", "casual", "creative", "technical"]
    description: "Content generation style"
  
  target_audience:
    type: "string"
    required: false
    default: "general"
    enum: ["general", "technical", "executive", "academic", "student"]
    description: "Target audience for content"
  
  quality_threshold:
    type: "number"
    required: false
    default: 0.8
    minimum: 0.0
    maximum: 1.0
    description: "Quality threshold for content acceptance (0-1)"
  
  max_iterations:
    type: "integer"
    required: false
    default: 3
    minimum: 1
    maximum: 10
    description: "Maximum refinement iterations"
  
  enable_translation:
    type: "boolean"
    required: false
    default: false
    description: "Enable multi-language translation"
  
  target_languages:
    type: "array"
    items: "string"
    required: false
    default: ["en"]
    description: "Target languages for translation"
    validation:
      allowed_values: ["en", "es", "fr", "de", "zh", "ja", "ko", "pt", "it", "ru"]

# Environment and API configurations
environment:
  # LLM APIs
  OPENAI_API_KEY: "required"
  ANTHROPIC_API_KEY: "optional"
  GOOGLE_API_KEY: "optional"
  
  # Specialized APIs
  STABILITY_API_KEY: "optional"    # Image generation
  ELEVEN_LABS_API_KEY: "optional" # TTS
  WHISPER_API_KEY: "optional"     # ASR
  RUNWAY_API_KEY: "optional"      # Video generation
  
  # Infrastructure
  REDIS_URL: "optional"           # Caching
  S3_BUCKET: "optional"          # File storage
  WEBHOOK_URL: "optional"        # Status notifications

# Advanced workflow with conditional logic and loops
workflow:
  type: "mixed"
  execution_strategy: "adaptive"
  
  # Global workflow variables
  variables:
    content_iteration_count: 0
    quality_score: 0.0
    processing_start_time: "{{ now() }}"
    
  nodes:
    # === INPUT PROCESSING PHASE ===
    
    # Document analysis and preprocessing
    - name: "analyze_documents"
      type: "document_processor"
      description: "Process and analyze input documents"
      condition: "{{ inputs.source_documents | length > 0 }}"
      config:
        operation: "extract_and_analyze"
        input_sources: "{{ inputs.source_documents }}"
        extraction_types: ["text", "metadata", "structure", "key_concepts"]
        analysis_depth: "comprehensive"
        chunk_size: 1000
        chunk_overlap: 200
      outputs:
        extracted_content: "$.extracted_text"
        document_metadata: "$.metadata" 
        key_concepts: "$.concepts"
        content_summary: "$.summary"
    
    # Multi-modal input analysis
    - name: "analyze_media"
      type: "multimodal_analyzer"
      description: "Analyze provided images and audio"
      condition: "{{ (inputs.reference_images | length > 0) or (inputs.audio_inputs | length > 0) }}"
      depends_on: ["analyze_documents"]
      config:
        image_analysis:
          enabled: "{{ inputs.reference_images | length > 0 }}"
          models: ["gpt-4-vision", "claude-3-opus"]
          analysis_types: ["description", "objects", "text_extraction", "sentiment", "style"]
          input_images: "{{ inputs.reference_images }}"
        audio_analysis:
          enabled: "{{ inputs.audio_inputs | length > 0 }}"
          transcription_model: "whisper-v3"
          audio_files: "{{ inputs.audio_inputs }}"
          analyze_sentiment: true
          extract_keywords: true
          detect_language: true
      outputs:
        image_descriptions: "$.image_analysis"
        transcribed_audio: "$.audio_transcripts"
        media_insights: "$.insights"

    # === CONTENT RESEARCH PHASE ===
    
    # Comprehensive research with web search
    - name: "research_content"
      type: "web_research"
      description: "Conduct comprehensive research on the topic"
      depends_on: ["analyze_documents", "analyze_media"]
      config:
        search_queries:
          - "{{ inputs.content_topic }} latest developments 2024"
          - "{{ inputs.content_topic }} expert opinions"
          - "{{ inputs.content_topic }} case studies examples"
        search_engines: ["google", "bing", "scholarly"]
        max_results_per_query: 10
        content_extraction:
          extract_key_points: true
          summarize_articles: true
          fact_check: true
        filters:
          date_range: "last_2_years"
          content_quality: "high"
          source_credibility: "verified"
      outputs:
        research_data: "$.search_results"
        key_findings: "$.key_points"
        source_credibility: "$.credibility_scores"
    
    # === CONTENT GENERATION PHASE ===
    
    # Initial content generation with loop for quality improvement
    - name: "generate_initial_content"
      type: "text_llm"
      description: "Generate initial content draft"
      depends_on: ["research_content"]
      config:
        model: "gpt-4-turbo"
        prompt: |
          Create comprehensive content about: {{ inputs.content_topic }}
          
          Target Audience: {{ inputs.target_audience }}
          Content Style: {{ inputs.content_style }}
          
          Available Research Data:
          {{ research_content_research_data }}
          
          Document Analysis (if available):
          {{ analyze_documents_content_summary | default('No document analysis available') }}
          
          Media Insights (if available):
          {{ analyze_media_media_insights | default('No media analysis available') }}
          
          Requirements:
          - Create engaging, accurate, and well-structured content
          - Include relevant examples and case studies
          - Ensure factual accuracy and cite key sources
          - Format for {{ inputs.target_audience }} audience
          - Length: 1500-2500 words
          
          Structure the content with:
          1. Executive Summary
          2. Main Content Sections (3-5 sections)
          3. Key Takeaways
          4. Recommendations
          5. References
        system: "You are an expert content creator with deep knowledge across domains. Create high-quality, engaging content that balances accuracy with accessibility."
        temperature: 0.6
        max_tokens: 3000
        timeout: "5m"
      outputs:
        draft_content: "$.response"
        generation_metadata: "$.metadata"
    
    # Content quality evaluation loop
    - name: "evaluate_content_quality"
      type: "text_llm"
      description: "Evaluate content quality and provide improvement suggestions"
      depends_on: ["generate_initial_content"]
      config:
        model: "gpt-4"
        prompt: |
          Evaluate the following content for quality, accuracy, and alignment with requirements:
          
          CONTENT TO EVALUATE:
          {{ generate_initial_content_draft_content }}
          
          EVALUATION CRITERIA:
          - Accuracy and factual correctness (0-1)
          - Clarity and readability (0-1) 
          - Engagement and interest (0-1)
          - Structure and organization (0-1)
          - Completeness and depth (0-1)
          - Alignment with target audience ({{ inputs.target_audience }}) (0-1)
          - Style consistency ({{ inputs.content_style }}) (0-1)
          
          Provide:
          1. Overall quality score (0-1, average of all criteria)
          2. Individual criterion scores
          3. Specific improvement suggestions
          4. Recommendation: ACCEPT/REVISE/REJECT
          
          Format as JSON:
          {
            "overall_score": 0.85,
            "criterion_scores": {
              "accuracy": 0.9,
              "clarity": 0.8,
              ...
            },
            "improvements": ["suggestion 1", "suggestion 2"],
            "recommendation": "ACCEPT"
          }
        system: "You are a strict content quality evaluator. Provide honest, detailed assessments."
        temperature: 0.2
        max_tokens: 1000
        response_format: "json"
      outputs:
        quality_assessment: "$.response"
        quality_score: "$.response.overall_score"
        recommendation: "$.response.recommendation"
    
    # Conditional content refinement loop
    - name: "refine_content"
      type: "loop"
      description: "Iteratively refine content until quality threshold is met"
      depends_on: ["evaluate_content_quality"]
      condition: "{{ evaluate_content_quality_quality_score < inputs.quality_threshold and content_iteration_count < inputs.max_iterations }}"
      config:
        loop_type: "while"
        max_iterations: "{{ inputs.max_iterations }}"
        condition: "{{ quality_score < inputs.quality_threshold }}"
        body:
          - name: "improve_content"
            type: "text_llm" 
            config:
              model: "gpt-4-turbo"
              prompt: |
                Improve the following content based on the quality assessment:
                
                CURRENT CONTENT:
                {{ generate_initial_content_draft_content }}
                
                QUALITY ASSESSMENT:
                {{ evaluate_content_quality_quality_assessment }}
                
                IMPROVEMENT AREAS:
                {{ evaluate_content_quality_quality_assessment.improvements }}
                
                Please revise the content addressing the specific improvement suggestions while maintaining the overall structure and key messages.
              temperature: 0.5
              max_tokens: 3000
            outputs:
              improved_content: "$.response"
          
          - name: "re_evaluate_quality"
            type: "text_llm"
            config:
              model: "gpt-4"
              prompt: |
                Re-evaluate the improved content using the same criteria as before:
                
                IMPROVED CONTENT:
                {{ improve_content_improved_content }}
                
                Provide updated quality scores and recommendation in the same JSON format.
              temperature: 0.2
              response_format: "json"
            outputs:
              updated_assessment: "$.response"
              updated_score: "$.response.overall_score"
        
        loop_variables:
          content_iteration_count: "{{ content_iteration_count + 1 }}"
          quality_score: "{{ re_evaluate_quality_updated_score }}"
          current_content: "{{ improve_content_improved_content }}"
      outputs:
        final_content: "$.current_content"
        final_quality_score: "$.quality_score"
        iteration_count: "$.content_iteration_count"

    # === MULTIMEDIA ENHANCEMENT PHASE ===
    
    # Generate supporting images
    - name: "generate_images"
      type: "image_generation"
      description: "Generate supporting images for content"
      depends_on: ["refine_content"]
      config:
        model: "dall-e-3"
        image_prompts:
          - "Professional illustration of {{ inputs.content_topic }}, modern clean style"
          - "Infographic elements related to {{ inputs.content_topic }}, minimalist design"
          - "Visual metaphor for {{ inputs.content_topic }}, abstract conceptual art"
        image_count: 3
        size: "1024x1024"
        quality: "hd"
        style: "vivid"
      outputs:
        generated_images: "$.image_urls"
        image_metadata: "$.metadata"
    
    # Text-to-speech generation  
    - name: "generate_audio"
      type: "text_to_speech"
      description: "Generate audio narration of content"
      depends_on: ["refine_content"]
      condition: "{{ inputs.target_audience == 'general' or inputs.target_audience == 'student' }}"
      config:
        model: "eleven-labs-v2"
        voice_id: "professional-narrator"
        text_input: "{{ refine_content_final_content }}"
        voice_settings:
          stability: 0.75
          similarity_boost: 0.5
          style: 0.25
        output_format: "mp3"
        quality: "high"
      outputs:
        audio_file: "$.audio_url"
        audio_duration: "$.duration_seconds"
    
    # === CONDITIONAL BRANCHING FOR SPECIALIZED CONTENT ===
    
    # Branch for technical audience - generate code examples
    - name: "generate_code_examples"
      type: "code_generator"
      description: "Generate relevant code examples for technical content"
      depends_on: ["refine_content"]
      condition: "{{ inputs.target_audience == 'technical' and inputs.content_topic contains 'technology' }}"
      config:
        programming_languages: ["python", "javascript", "rust"]
        code_types: ["examples", "demos", "snippets"]
        context: "{{ refine_content_final_content }}"
        documentation_level: "detailed"
        include_tests: true
      outputs:
        code_examples: "$.generated_code"
        code_documentation: "$.documentation"
    
    # Branch for academic audience - generate citations and references
    - name: "generate_academic_references"
      type: "reference_generator"
      description: "Generate proper academic references and citations"
      depends_on: ["research_content", "refine_content"]
      condition: "{{ inputs.target_audience == 'academic' }}"
      config:
        citation_style: "APA"
        sources: "{{ research_content_research_data }}"
        content: "{{ refine_content_final_content }}"
        include_bibliography: true
        verify_citations: true
      outputs:
        formatted_citations: "$.citations"
        bibliography: "$.bibliography"
        citation_count: "$.count"

    # === TRANSLATION PHASE (CONDITIONAL) ===
    
    - name: "translate_content"
      type: "translator"
      description: "Translate content to target languages"
      depends_on: ["refine_content"]
      condition: "{{ inputs.enable_translation and inputs.target_languages | length > 1 }}"
      config:
        source_language: "auto-detect"
        target_languages: "{{ inputs.target_languages }}"
        content: "{{ refine_content_final_content }}"
        translation_model: "gpt-4"
        preserve_formatting: true
        cultural_adaptation: true
      outputs:
        translated_content: "$.translations"
        language_metadata: "$.language_info"

    # === ADVANCED PROCESSING WITH BATCH OPERATIONS ===
    
    # Batch process multiple content variations
    - name: "generate_content_variations"
      type: "batch"
      description: "Generate multiple content variations for A/B testing"
      depends_on: ["refine_content"]
      config:
        batch_size: 3
        parallel_limit: 2
        items_source: '["variation_1", "variation_2", "variation_3"]'
        processor:
          type: "text_llm"
          config:
            model: "gpt-4"
            prompt: |
              Create a variation of this content with a different approach/angle:
              
              Original Content: {{ refine_content_final_content }}
              Variation Type: {{ item }}
              
              Maintain the core message but change:
              - Opening hook and narrative style
              - Example selection and case studies  
              - Structural organization
              - Tone and voice (while staying within {{ inputs.content_style }} style)
            temperature: 0.7
            max_tokens: 2500
      outputs:
        content_variations: "$.batch_results"
        variation_count: "$.processed_count"

    # === QUALITY ASSURANCE AND VALIDATION ===
    
    - name: "final_validation"
      type: "validator"
      description: "Comprehensive final validation of all generated content"
      depends_on: ["generate_images", "generate_audio", "generate_content_variations"]
      config:
        validation_checks:
          content_quality:
            min_score: "{{ inputs.quality_threshold }}"
            current_score: "{{ refine_content_final_quality_score }}"
          completeness:
            required_sections: ["summary", "main_content", "takeaways"]
            content: "{{ refine_content_final_content }}"
          media_assets:
            required_images: 1
            available_images: "{{ generate_images_generated_images | length }}"
            audio_required: "{{ inputs.target_audience in ['general', 'student'] }}"
            audio_available: "{{ generate_audio_audio_file != null }}"
          translations:
            required: "{{ inputs.enable_translation }}"
            available_languages: "{{ translate_content_translated_content | keys | length }}"
        failure_action: "log_and_continue"
      outputs:
        validation_results: "$.results"
        validation_passed: "$.all_checks_passed"
        validation_errors: "$.errors"

    # === OUTPUT PREPARATION ===
    
    - name: "prepare_final_outputs"
      type: "output_formatter"
      description: "Format and prepare all outputs for delivery"
      depends_on: ["final_validation"]
      config:
        output_formats:
          main_content:
            format: "markdown"
            include_metadata: true
            include_toc: true
            content: "{{ refine_content_final_content }}"
          multimedia_package:
            images: "{{ generate_images_generated_images }}"
            audio: "{{ generate_audio_audio_file }}"
            format: "structured_archive"
          quality_report:
            format: "json"
            include:
              - final_quality_score: "{{ refine_content_final_quality_score }}"
              - iteration_count: "{{ refine_content_iteration_count }}"
              - validation_results: "{{ final_validation_validation_results }}"
              - processing_time: "{{ now() - processing_start_time }}"
        packaging:
          create_archive: true
          include_metadata: true
          compression: "zip"
      outputs:
        formatted_content: "$.main_content"
        multimedia_package: "$.multimedia"
        quality_report: "$.quality_report"
        final_archive: "$.archive_path"

# Comprehensive output definitions
outputs:
  # Primary content outputs
  final_content:
    source: "{{ prepare_final_outputs_formatted_content }}"
    format: "markdown"
    file: "output/{{ inputs.content_topic | slugify }}_final_content.md"
    metadata:
      quality_score: "{{ refine_content_final_quality_score }}"
      iteration_count: "{{ refine_content_iteration_count }}"
      target_audience: "{{ inputs.target_audience }}"
      content_style: "{{ inputs.content_style }}"
  
  # Content variations for A/B testing
  content_variations:
    source: "{{ generate_content_variations_content_variations }}"
    format: "json"
    file: "output/content_variations.json"
  
  # Multimedia assets
  generated_images:
    source: "{{ generate_images_generated_images }}"
    format: "json"
    file: "output/generated_images.json"
    copy_files: true
    destination: "output/images/"
  
  audio_narration:
    source: "{{ generate_audio_audio_file }}"
    format: "file"
    file: "output/audio/narration.mp3"
    condition: "{{ generate_audio_audio_file != null }}"
  
  # Research and analysis outputs
  research_summary:
    source: "{{ research_content_key_findings }}"
    format: "json"
    file: "output/research_summary.json"
  
  # Translations (conditional)
  translated_content:
    source: "{{ translate_content_translated_content }}"
    format: "json"
    file: "output/translations.json"
    condition: "{{ inputs.enable_translation }}"
  
  # Technical outputs (conditional)
  code_examples:
    source: "{{ generate_code_examples_code_examples }}"
    format: "json"
    file: "output/code_examples.json"
    condition: "{{ inputs.target_audience == 'technical' }}"
  
  # Academic outputs (conditional)  
  academic_references:
    source: "{{ generate_academic_references_bibliography }}"
    format: "text"
    file: "output/bibliography.txt"
    condition: "{{ inputs.target_audience == 'academic' }}"
  
  # Quality and execution reports
  quality_report:
    source: "{{ prepare_final_outputs_quality_report }}"
    format: "json"
    file: "output/quality_report.json"
    include:
      - execution_time
      - quality_metrics
      - validation_results
      - resource_usage
  
  execution_log:
    source: "$"
    format: "json"
    file: "output/execution_log.json"
    include:
      - workflow_metadata
      - node_execution_times
      - error_logs
      - shared_state_snapshots
  
  # Complete package
  complete_package:
    source: "{{ prepare_final_outputs_final_archive }}"
    format: "file"
    file: "output/{{ inputs.content_topic | slugify }}_complete_package.zip"
    description: "Complete package with all generated content and assets"

# Advanced workflow control and error handling
error_handling:
  on_node_failure:
    strategy: "continue_with_fallback"
    log_level: "error"
    notify_webhook: true
  
  fallback_strategies:
    text_llm_failure:
      fallback_models: ["gpt-3.5-turbo", "claude-3-sonnet"]
      retry_count: 2
    
    image_generation_failure:
      skip_node: true
      log_warning: "Image generation failed, continuing without images"
    
    translation_failure:
      skip_translations: true
      continue_workflow: true

# Monitoring and observability
observability:
  metrics:
    enabled: true
    export_format: "prometheus"
    custom_metrics:
      - content_quality_score
      - processing_duration
      - api_call_count
      - resource_utilization
  
  tracing:
    enabled: true
    sample_rate: 1.0
    export_traces: true
  
  logging:
    level: "info"
    structured: true
    include_shared_state: true
    log_node_outputs: false  # For privacy

# Resource management
resources:
  compute:
    cpu_limit: "4"
    memory_limit: "4Gi"
    gpu_limit: "1"
  
  storage:
    temp_storage: "10Gi"
    output_storage: "5Gi"
    cache_storage: "2Gi"
  
  api_limits:
    openai:
      requests_per_minute: 50
      tokens_per_minute: 150000
    anthropic:
      requests_per_minute: 40
      tokens_per_minute: 100000

# Security and compliance
security:
  api_key_rotation: true
  encrypt_sensitive_data: true
  audit_log: true
  content_filtering:
    enabled: true
    filters: ["harmful", "biased", "inappropriate"]
    action: "flag_and_continue"

# Caching and optimization
caching:
  enabled: true
  cache_ttl: "24h"
  cache_strategy: "content_hash"
  cache_nodes:
    - "research_content"
    - "generate_images"
    - "translate_content"