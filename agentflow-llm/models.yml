# Example model configuration file
# Copy this to your project root and configure with your API keys

models:
  # OpenAI Models
  gpt-4o:
    vendor: openai
    base_url: "https://api.openai.com/v1"
    temperature: 0.7
    top_p: 0.9
    max_tokens: 4096
    frequency_penalty: 0.0
    stop: ["\n\n", "User:"]
    n: 1
    supports_streaming: true
    supports_tools: true
    supports_multimodal: true
    response_format: "text"

  gpt-4o-mini:
    vendor: openai
    base_url: "https://api.openai.com/v1"
    temperature: 0.7
    max_tokens: 4096
    supports_streaming: true

  gpt-4-turbo:
    vendor: openai
    model_id: "gpt-4-turbo-preview"
    temperature: 0.8
    max_tokens: 4096

  # Anthropic Models
  claude-3-5-sonnet:
    vendor: anthropic
    model_id: "claude-3-5-sonnet-20241022"
    temperature: 0.6
    max_tokens: 8192
    frequency_penalty: 0.0
    supports_streaming: true
    supports_tools: true
    supports_multimodal: true

  claude-3-sonnet:
    vendor: anthropic
    model_id: "claude-3-sonnet-20240229"
    temperature: 0.5
    max_tokens: 4096

  claude-3-haiku:
    vendor: anthropic
    model_id: "claude-3-haiku-20240307"
    temperature: 0.3
    max_tokens: 4096
    supports_streaming: true

  # Google Gemini Models
  gemini-1.5-pro:
    vendor: google
    temperature: 0.7
    max_tokens: 8192
    top_p: 0.9
    supports_streaming: true
    supports_tools: true
    supports_multimodal: true

  gemini-1.5-flash:
    vendor: google
    temperature: 0.8
    max_tokens: 8192
    supports_streaming: true

  gemini-1.0-pro:
    vendor: google
    temperature: 0.5
    max_tokens: 4096

  # Moonshot Models
  moonshot-v1-8k:
    vendor: moonshot
    temperature: 0.7
    max_tokens: 8192
    supports_streaming: true

  moonshot-v1-32k:
    vendor: moonshot
    temperature: 0.7
    max_tokens: 32768
    supports_streaming: true

  moonshot-v1-128k:
    vendor: moonshot
    temperature: 0.7
    max_tokens: 131072
    supports_streaming: true

  # Step Models
  step-1v-8k:
    vendor: step
    temperature: 0.7
    max_tokens: 8192
    supports_streaming: true
    supports_multimodal: true

  step-1v-32k:
    vendor: step
    temperature: 0.7
    max_tokens: 32768
    supports_streaming: true
    supports_multimodal: true

  step-2-mini:
    vendor: step
    temperature: 0.7
    max_tokens: 16384
    supports_streaming: true
    supports_tools: true
    supports_multimodal: false

  step-2-16k:
    vendor: step
    temperature: 0.7
    max_tokens: 16384
    supports_streaming: true
    supports_tools: true
    supports_multimodal: true

  step-3:
    vendor: step
    temperature: 0.7
    max_tokens: 32768
    supports_streaming: true
    supports_tools: true
    supports_multimodal: false

# Provider configurations
providers:
  openai:
    api_key_env: "OPENAI_API_KEY"
    base_url: "https://api.openai.com/v1"
    timeout_seconds: 60
    rate_limit:
      requests_per_minute: 500
      tokens_per_minute: 80000

  anthropic:
    api_key_env: "ANTHROPIC_API_KEY"
    base_url: "https://api.anthropic.com"
    timeout_seconds: 90
    rate_limit:
      requests_per_minute: 300
      tokens_per_minute: 40000

  google:
    api_key_env: "GOOGLE_API_KEY"
    base_url: "https://generativelanguage.googleapis.com"
    timeout_seconds: 60
    rate_limit:
      requests_per_minute: 1000
      tokens_per_minute: 32000

  moonshot:
    api_key_env: "MOONSHOT_API_KEY"
    base_url: "https://api.moonshot.cn/v1"
    timeout_seconds: 60
    rate_limit:
      requests_per_minute: 300
      tokens_per_minute: 20000

  step:
    api_key_env: "STEP_API_KEY"
    base_url: "https://api.stepfun.com/v1"
    timeout_seconds: 60
    rate_limit:
      requests_per_minute: 300
      tokens_per_minute: 20000

# Global defaults
defaults:
  timeout_seconds: 60
  max_retries: 3
  retry_delay_ms: 1000