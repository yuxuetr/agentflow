use serde_json::json;
use std::env;

/// Comprehensive StepFun API demonstration covering all model types
///
/// This example demonstrates the proper usage patterns for each StepFun model category:
/// - Text models via LLMClient (chat completions)
/// - Image understanding via LLMClient (multimodal chat)
/// - Multimodal via LLMClient (enhanced chat)
/// - TTS, ASR, Image generation via StepFunSpecializedClient
///
/// Set STEP_API_KEY environment variable before running:
/// ```
/// export STEP_API_KEY="your-stepfun-api-key-here"
/// cargo run --example stepfun_comprehensive_demo
/// ```
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
  // Initialize environment and logging
  env_logger::init();

  let api_key = env::var("STEP_API_KEY").expect("STEP_API_KEY environment variable is required");

  println!("ğŸš€ StepFun Comprehensive API Demo - Reference Implementation");
  println!("============================================================\n");
  println!(
    "This demo shows the correct API patterns and request structures for each StepFun model type."
  );
  println!("For actual working examples, see the individual test files:\n");
  println!("  â€¢ stepfun_text_models.rs - Real text API tests");
  println!("  â€¢ stepfun_image_understanding.rs - Real image understanding tests");
  println!("  â€¢ stepfun_tts_models.rs - Real TTS API tests");
  println!("  â€¢ stepfun_asr_models.rs - Real ASR API tests");
  println!("  â€¢ stepfun_image_generation.rs - Real image generation tests\n");

  // Demo 1: Text Models (Chat Completions)
  demo_text_models(&api_key).await?;

  // Demo 2: Image Understanding
  demo_image_understanding(&api_key).await?;

  // Demo 3: Multimodal
  demo_multimodal(&api_key).await?;

  // Demo 4: Text-to-Speech (TTS)
  demo_text_to_speech(&api_key).await?;

  // Demo 5: Automatic Speech Recognition (ASR)
  demo_speech_recognition(&api_key).await?;

  // Demo 6: Image Generation
  demo_image_generation(&api_key).await?;

  // Demo 7: Image Editing
  demo_image_editing(&api_key).await?;

  // Demo 8: Voice Cloning
  demo_voice_cloning(&api_key).await?;

  println!("âœ… All API patterns demonstrated successfully!");
  println!("ğŸ“‹ To run actual tests, use the individual example files listed above.");
  Ok(())
}

/// Demo 1: Text Models - Standard chat completions
async fn demo_text_models(_api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
  println!("ğŸ“ Demo 1: Text Models (Chat Completions)");
  println!("Models: step-1-8k, step-1-32k, step-2-16k, step-2-mini\n");

  // Show non-streaming request structure
  println!("ğŸ“¤ Non-streaming request structure:");
  let non_streaming_request = json!({
      "model": "step-2-16k",
      "messages": [
          {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¨‹åºå‘˜ã€‚"},
          {"role": "user", "content": "ç”¨Pythonå†™å¿«é€Ÿæ’åºç®—æ³•"}
      ],
      "max_tokens": 1000,
      "temperature": 0.7,
      "stream": false
  });
  println!("   Endpoint: POST /v1/chat/completions");
  println!(
    "   Request body: {}",
    serde_json::to_string_pretty(&non_streaming_request)?
  );

  // Show streaming request structure
  println!("\nğŸ“¤ Streaming request structure:");
  let streaming_request = json!({
      "model": "step-1-32k",
      "messages": [
          {"role": "user", "content": "è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†"}
      ],
      "stream": true,
      "max_tokens": 800,
      "temperature": 0.8
  });
  println!("   Endpoint: POST /v1/chat/completions");
  println!(
    "   Request body: {}",
    serde_json::to_string_pretty(&streaming_request)?
  );
  println!("   Response: Server-Sent Events (SSE) stream");

  println!("âœ… Text models API pattern demonstrated\n");
  Ok(())
}

/// Demo 2: Image Understanding - Vision models with chat completions
async fn demo_image_understanding(_api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
  println!("ğŸ–¼ï¸  Demo 2: Image Understanding");
  println!("Models: step-1o-turbo-vision, step-1v-8k, step-1v-32k\n");

  // Show multimodal request structure
  println!("ğŸ“¤ Image understanding request structure:");
  let vision_request = json!({
      "model": "step-1o-turbo-vision",
      "messages": [
          {
              "role": "user",
              "content": [
                  {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦å…ƒç´ å’Œæ•´ä½“æ„å›¾"},
                  {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}}
              ]
          }
      ],
      "max_tokens": 500,
      "temperature": 0.7
  });

  println!("   Endpoint: POST /v1/chat/completions");
  println!(
    "   Request body: {}",
    serde_json::to_string_pretty(&vision_request)?
  );

  println!("\nğŸ“ Key features:");
  println!("   â€¢ Uses same chat completions endpoint as text models");
  println!("   â€¢ Content array format with type field");
  println!("   â€¢ Supports both image URLs and base64 encoding");
  println!("   â€¢ Compatible with streaming (add \"stream\": true)");

  println!("âœ… Image understanding API pattern demonstrated\n");
  Ok(())
}

/// Demo 3: Multimodal - Advanced multimodal capabilities
async fn demo_multimodal(_api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
  println!("ğŸ­ Demo 3: Multimodal");
  println!("Models: step-3\n");

  println!("ğŸ“¤ Multimodal request structure:");

  // Multimodal models use the same chat completions endpoint but with enhanced capabilities
  let multimodal_request = json!({
      "model": "step-3",
      "messages": [
          {
              "role": "system",
              "content": "ä½ æ˜¯ä¸€ä¸ªå…·æœ‰å¤šæ¨¡æ€ç†è§£èƒ½åŠ›çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿç»¼åˆåˆ†æå¤šç§ç±»å‹çš„å†…å®¹ã€‚"
          },
          {
              "role": "user",
              "content": [
                  {"type": "text", "text": "åˆ†æè¿™äº›å›¾ç‰‡çš„å·®å¼‚ï¼Œæ¯”è¾ƒå®ƒä»¬çš„ç‰¹ç‚¹"},
                  {"type": "image_url", "image_url": {"url": "https://example.com/image1.jpg"}},
                  {"type": "image_url", "image_url": {"url": "https://example.com/image2.jpg"}}
              ]
          }
      ],
      "max_tokens": 700,
      "temperature": 0.8
  });

  println!("   Endpoint: POST /v1/chat/completions");
  println!(
    "   Request body: {}",
    serde_json::to_string_pretty(&multimodal_request)?
  );

  println!("\nğŸ“ Multimodal capabilities:");
  println!("   â€¢ Multiple image processing in single request");
  println!("   â€¢ Enhanced reasoning and comparison");
  println!("   â€¢ Cross-modal understanding");
  println!("   â€¢ Same API format as basic vision models");
  println!("âœ… Multimodal API pattern demonstrated\n");

  Ok(())
}

/// Demo 4: Text-to-Speech - Audio synthesis
async fn demo_text_to_speech(_api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
  println!("ğŸ”Š Demo 4: Text-to-Speech (TTS)");
  println!("Models: step-tts-vivid, step-tts-mini\n");

  // Show TTS request structure
  println!("ğŸ“¤ TTS request structure:");
  let tts_request = json!({
      "model": "step-tts-vivid",
      "input": "æ™ºèƒ½é˜¶è·ƒï¼Œåå€æ¯ä¸€ä¸ªäººçš„å¯èƒ½",
      "voice": "cixingnansheng",
      "response_format": "mp3",
      "speed": 1.0,
      "volume": 1.0,
      "voice_label": {
          "emotion": "é«˜å…´"
      },
      "sample_rate": 24000
  });

  println!("   Endpoint: POST /v1/audio/speech");
  println!(
    "   Request body: {}",
    serde_json::to_string_pretty(&tts_request)?
  );

  println!("\nğŸ“ Key features:");
  println!("   â€¢ Dedicated audio synthesis endpoint");
  println!("   â€¢ Multiple output formats (MP3, WAV, OPUS, FLAC)");
  println!("   â€¢ Voice customization with emotion and style");
  println!("   â€¢ Chinese voice optimization");
  println!("   â€¢ Returns binary audio data");

  println!("âœ… TTS API pattern demonstrated\n");

  Ok(())
}

/// Demo 5: Speech Recognition - Audio transcription
async fn demo_speech_recognition(_api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
  println!("ğŸ¤ Demo 5: Automatic Speech Recognition (ASR)");
  println!("Models: step-asr\n");

  println!("ğŸ“¤ ASR request structure:");
  println!("   Endpoint: POST /v1/audio/transcriptions");
  println!("   Content-Type: multipart/form-data");
  println!("   Method: Form upload with audio file");

  println!("\nğŸ“‹ Form data parameters:");
  println!("   â€¢ file: Audio file (WAV/MP3/FLAC)");
  println!("   â€¢ model: \"step-asr\"");
  println!("   â€¢ response_format: \"json\" | \"text\" | \"srt\" | \"vtt\"");

  println!("\nğŸ“ Response format examples:");
  println!("   JSON: {{\"text\": \"transcribed content\"}}");
  println!("   Text: Raw transcribed text");
  println!("   SRT: SubRip subtitle format with timestamps");
  println!("   VTT: WebVTT format for web videos");

  println!("\nğŸ“ Key features:");
  println!("   â€¢ Multipart form data upload");
  println!("   â€¢ Multiple response formats including subtitles");
  println!("   â€¢ Optimized for Chinese speech recognition");

  println!("âœ… ASR API pattern demonstrated\n");

  Ok(())
}

/// Demo 6: Image Generation - Text to image
async fn demo_image_generation(_api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
  println!("ğŸ¨ Demo 6: Image Generation");
  println!("Models: step-2x-large, step-1x-medium\n");

  // Show image generation request structure
  println!("ğŸ“¤ Image generation request structure:");
  let image_request = json!({
      "model": "step-2x-large",
      "prompt": "æœªæ¥ç§‘æŠ€åŸå¸‚å¤œæ™¯ï¼Œéœ“è™¹ç¯é—ªçƒï¼Œèµ›åšæœ‹å…‹é£æ ¼ï¼Œé«˜è´¨é‡ï¼Œ4Kè¶…æ¸…",
      "size": "1024x1024",
      "n": 1,
      "response_format": "b64_json",
      "seed": 12345,
      "steps": 50,
      "cfg_scale": 7.5,
      "style_reference": {
          "source_url": "https://example.com/style.jpg",
          "weight": 1.0
      }
  });

  println!("   Endpoint: POST /v1/images/generations");
  println!(
    "   Request body: {}",
    serde_json::to_string_pretty(&image_request)?
  );

  println!("\nğŸ“ Key features:");
  println!("   â€¢ Specialized image generation endpoint");
  println!("   â€¢ Style reference support for consistent aesthetics");
  println!("   â€¢ Multiple output formats (base64 or URL)");
  println!("   â€¢ Fine-grained control over generation parameters");
  println!("   â€¢ Reproducible results with seed parameter");

  println!("âœ… Image generation API pattern demonstrated\n");

  Ok(())
}

/// Demo 7: Image Editing - AI-powered image modification
async fn demo_image_editing(_api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
  println!("âœ‚ï¸  Demo 7: Image Editing");
  println!("Models: step-1x-edit\n");

  println!("ğŸ“¤ Image editing request structure:");
  println!("   Endpoint: POST /v1/images/edits");
  println!("   Content-Type: multipart/form-data");
  println!("   Method: Form upload with image file");

  println!("\nğŸ“‹ Form data parameters:");
  println!("   â€¢ model: \"step-1x-edit\"");
  println!("   â€¢ image: Image file (JPG/PNG)");
  println!("   â€¢ prompt: \"æ·»åŠ å½©è™¹æ•ˆæœï¼Œè®©ç”»é¢æ›´åŠ æ¢¦å¹»å’Œè‰²å½©ä¸°å¯Œ\"");
  println!("   â€¢ response_format: \"url\" | \"b64_json\"");
  println!("   â€¢ seed: 12345 (optional, for reproducibility)");
  println!("   â€¢ steps: 28 (optional, default 28)");
  println!("   â€¢ cfg_scale: 6.0 (optional, default 6)");
  println!("   â€¢ size: \"512x512\" | \"768x768\" | \"1024x1024\"");

  println!("\nğŸ“ Key features:");
  println!("   â€¢ Multipart form data for image upload");
  println!("   â€¢ Text-guided image editing");
  println!("   â€¢ Preserves original image structure");
  println!("   â€¢ AI-powered enhancement and modification");

  println!("âœ… Image editing API pattern demonstrated\n");

  Ok(())
}

/// Demo 8: Voice Cloning - Custom voice profile creation
async fn demo_voice_cloning(_api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
  println!("ğŸ­ Demo 8: Voice Cloning");
  println!("Models: step-tts-vivid (for voice creation)\n");

  println!("ğŸ“¤ Voice cloning workflow:");
  println!("   Step 1: Create voice profile");
  println!("   Endpoint: POST /v1/audio/voices");

  // Show voice cloning request structure
  let voice_request = json!({
      "model": "step-tts-vivid",
      "file_id": "file-abc123",  // From previous file upload
      "text": "è¿™æ˜¯ç”¨äºè®­ç»ƒçš„å£°éŸ³æ ·æœ¬ï¼Œè¯·è¯´å‡ºè¿™æ®µæ–‡å­—",
      "sample_text": "æµ‹è¯•ç”¨çš„æ ·æœ¬æ–‡æœ¬"
  });

  println!(
    "   Request body: {}",
    serde_json::to_string_pretty(&voice_request)?
  );

  println!("\n   Step 2: Use cloned voice in TTS");
  let tts_with_clone = json!({
      "model": "step-tts-vivid",
      "input": "ä½¿ç”¨å…‹éš†å£°éŸ³åˆæˆçš„æ–°æ–‡æœ¬å†…å®¹",
      "voice": "voice-tone-xyz789",  // Use cloned voice ID from copyvoices API
      "response_format": "mp3"
  });

  println!("   Endpoint: POST /v1/audio/speech");
  println!(
    "   Request body: {}",
    serde_json::to_string_pretty(&tts_with_clone)?
  );

  println!("\nğŸ“ Key features:");
  println!("   â€¢ Creates custom voice profiles from audio samples");
  println!("   â€¢ Returns voice ID for use in TTS requests");
  println!("   â€¢ Includes sample audio playback for verification");
  println!("   â€¢ Two-step process: profile creation â†’ voice synthesis");

  println!("âœ… Voice cloning API pattern demonstrated\n");

  Ok(())
}

// Example configuration for running the demos
//
// ```bash
// # Set environment variable
// export STEP_API_KEY="sk-your-stepfun-api-key-here"
//
// # Run the comprehensive demo
// cargo run --example stepfun_comprehensive_demo
//
// # Or run with verbose logging
// RUST_LOG=debug cargo run --example stepfun_comprehensive_demo
// ```
//
// Expected output structure:
// - Each demo section shows the correct API pattern
// - Request structures match the real API requirements
// - Model routing is validated for each category
// - Error handling demonstrates proper usage patterns
