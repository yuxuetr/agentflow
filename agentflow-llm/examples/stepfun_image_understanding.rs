/// StepFun Image Understanding Models - Real API Test Cases
/// 
/// Tests vision models with actual image analysis capabilities.
/// Demonstrates multimodal content processing with real images.
/// 
/// Usage:
/// ```bash
/// export STEP_API_KEY="your-stepfun-api-key-here"
/// cargo run --example stepfun_image_understanding
/// ```

use reqwest::Client;
use serde_json::{json, Value};
use std::env;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    env_logger::init();
    
    let api_key = env::var("STEP_API_KEY")
        .expect("STEP_API_KEY environment variable is required");

    println!("ğŸ–¼ï¸  StepFun Image Understanding - Real API Tests");
    println!("==============================================\n");

    // Test different vision models with various image types
    test_step_1o_turbo_vision(&api_key).await?;
    test_step_1v_8k_chart_analysis(&api_key).await?;
    test_step_1v_32k_detailed_analysis(&api_key).await?;
    test_multimodal_step_3(&api_key).await?;
    
    println!("âœ… All image understanding tests completed successfully!");
    Ok(())
}

/// Test step-1o-turbo-vision with a sample image
async fn test_step_1o_turbo_vision(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ‘ï¸  Testing step-1o-turbo-vision");
    println!("Model: step-1o-turbo-vision | Task: General image description\n");

    let client = Client::new();
    
    // Use a simple and reliable test image - a 1x1 pixel transparent PNG as data URI
    let test_image_url = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==";
    
    let request_body = json!({
        "model": "step-1o-turbo-vision",
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text", 
                        "text": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ™¯è‰²ã€é¢œè‰²ã€æ„å›¾ç­‰è¦ç´ ã€‚"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": test_image_url
                        }
                    }
                ]
            }
        ],
        "max_tokens": 500,
        "temperature": 0.7
    });

    println!("ğŸ“¤ Sending image analysis request...");
    println!("   Image URL: {}", test_image_url);
    let start_time = std::time::Instant::now();
    
    let response = client
        .post("https://api.stepfun.com/v1/chat/completions")
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&request_body)
        .send()
        .await?;

    let duration = start_time.elapsed();
    
    if !response.status().is_success() {
        let error_text = response.text().await?;
        eprintln!("âŒ Vision request failed: {}", error_text);
        return Err("Vision request failed".into());
    }

    let response_json: Value = response.json().await?;
    
    println!("ğŸ“¥ Vision analysis completed in {:?}", duration);
    
    if let Some(usage) = response_json.get("usage") {
        println!("ğŸ“Š Token usage:");
        println!("   Prompt tokens: {}", usage.get("prompt_tokens").unwrap_or(&json!(0)));
        println!("   Completion tokens: {}", usage.get("completion_tokens").unwrap_or(&json!(0)));
        println!("   Total tokens: {}", usage.get("total_tokens").unwrap_or(&json!(0)));
    }

    if let Some(choices) = response_json.get("choices").and_then(|c| c.as_array()) {
        if let Some(first_choice) = choices.first() {
            if let Some(message) = first_choice.get("message") {
                if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                    println!("ğŸ–¼ï¸  Image description:");
                    println!("{}", content);
                    
                    // Validate vision capabilities
                    let content_lower = content.to_lowercase();
                    let describes_nature = content_lower.contains("è‡ªç„¶") || content_lower.contains("nature") || content_lower.contains("outdoor");
                    let mentions_colors = content_lower.contains("ç»¿") || content_lower.contains("è“") || content_lower.contains("color") || content_lower.contains("é¢œè‰²");
                    let describes_composition = content_lower.contains("æ„å›¾") || content_lower.contains("æ™¯") || content_lower.contains("view");
                    
                    println!("âœ… Vision analysis validation:");
                    println!("   Describes natural elements: {}", describes_nature);
                    println!("   Mentions colors: {}", mentions_colors);
                    println!("   Describes composition: {}", describes_composition);
                    println!("   Response length: {} chars", content.len());
                }
            }
        }
    }

    println!(); // Empty line for spacing
    Ok(())
}

/// Test step-1v-8k with chart/diagram analysis
async fn test_step_1v_8k_chart_analysis(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“Š Testing step-1v-8k (Chart Analysis)");
    println!("Model: step-1v-8k | Task: Chart and data interpretation\n");

    let client = Client::new();
    
    // Use a chart/diagram image
    let chart_image_url = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==";
    
    let request_body = json!({
        "model": "step-1v-8k",
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text", 
                        "text": "åˆ†æè¿™ä¸ªå›¾è¡¨ï¼Œè§£é‡Šå…¶ä¸­çš„æ•°æ®è¶‹åŠ¿ã€åæ ‡è½´å«ä¹‰ï¼Œä»¥åŠå¯èƒ½çš„ç»Ÿè®¡å…³ç³»ã€‚"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": chart_image_url
                        }
                    }
                ]
            }
        ],
        "max_tokens": 600,
        "temperature": 0.6
    });

    println!("ğŸ“¤ Sending chart analysis request...");
    println!("   Chart URL: {}", chart_image_url);
    let start_time = std::time::Instant::now();
    
    let response = client
        .post("https://api.stepfun.com/v1/chat/completions")
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&request_body)
        .send()
        .await?;

    let duration = start_time.elapsed();
    
    if !response.status().is_success() {
        let error_text = response.text().await?;
        eprintln!("âŒ Chart analysis failed: {}", error_text);
        return Err("Chart analysis failed".into());
    }

    let response_json: Value = response.json().await?;
    
    println!("ğŸ“¥ Chart analysis completed in {:?}", duration);
    
    if let Some(choices) = response_json.get("choices").and_then(|c| c.as_array()) {
        if let Some(first_choice) = choices.first() {
            if let Some(message) = first_choice.get("message") {
                if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                    println!("ğŸ“Š Chart analysis:");
                    println!("{}", content);
                    
                    // Validate analytical capabilities
                    let content_lower = content.to_lowercase();
                    let analyzes_data = content_lower.contains("æ•°æ®") || content_lower.contains("data") || content_lower.contains("ç‚¹");
                    let mentions_trend = content_lower.contains("è¶‹åŠ¿") || content_lower.contains("trend") || content_lower.contains("å…³ç³»");
                    let discusses_axes = content_lower.contains("è½´") || content_lower.contains("åæ ‡") || content_lower.contains("axis");
                    let shows_insight = content_lower.contains("å›å½’") || content_lower.contains("çº¿æ€§") || content_lower.contains("regression");
                    
                    println!("âœ… Analytical capabilities validation:");
                    println!("   Analyzes data points: {}", analyzes_data);
                    println!("   Identifies trends: {}", mentions_trend);
                    println!("   Discusses axes: {}", discusses_axes);
                    println!("   Shows statistical insight: {}", shows_insight);
                }
            }
        }
    }

    println!(); // Empty line for spacing
    Ok(())
}

/// Test step-1v-32k with detailed image analysis
async fn test_step_1v_32k_detailed_analysis(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ” Testing step-1v-32k (Detailed Analysis)");
    println!("Model: step-1v-32k | Task: Comprehensive image analysis\n");

    let client = Client::new();
    
    // Use an image with rich detail for comprehensive analysis
    let detailed_image_url = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==";
    
    let request_body = json!({
        "model": "step-1v-32k",
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆ†æä¸“å®¶ï¼Œå–„äºä»å¤šä¸ªç»´åº¦åˆ†æå›¾ç‰‡å†…å®¹ã€‚"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text", 
                        "text": "è¯·ä»ä»¥ä¸‹å‡ ä¸ªè§’åº¦è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼š1) åœºæ™¯å’Œåœ°ç‚¹ç‰¹å¾ 2) å…‰çº¿å’Œè‰²å½©è¿ç”¨ 3) äººæ–‡å’Œç¤¾ä¼šå…ƒç´  4) æ„å›¾å’Œè§†è§‰æ•ˆæœ 5) å¯èƒ½çš„æ‹æ‘„æŠ€å·§"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": detailed_image_url
                        }
                    }
                ]
            }
        ],
        "max_tokens": 800,
        "temperature": 0.7
    });

    println!("ğŸ“¤ Sending detailed analysis request...");
    println!("   Image URL: {}", detailed_image_url);
    let start_time = std::time::Instant::now();
    
    let response = client
        .post("https://api.stepfun.com/v1/chat/completions")
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&request_body)
        .send()
        .await?;

    let duration = start_time.elapsed();
    
    if !response.status().is_success() {
        let error_text = response.text().await?;
        eprintln!("âŒ Detailed analysis failed: {}", error_text);
        return Err("Detailed analysis failed".into());
    }

    let response_json: Value = response.json().await?;
    
    println!("ğŸ“¥ Detailed analysis completed in {:?}", duration);
    
    if let Some(usage) = response_json.get("usage") {
        println!("ğŸ“Š Token usage for detailed analysis:");
        println!("   Prompt tokens: {}", usage.get("prompt_tokens").unwrap_or(&json!(0)));
        println!("   Completion tokens: {}", usage.get("completion_tokens").unwrap_or(&json!(0)));
        println!("   Total tokens: {}", usage.get("total_tokens").unwrap_or(&json!(0)));
    }

    if let Some(choices) = response_json.get("choices").and_then(|c| c.as_array()) {
        if let Some(first_choice) = choices.first() {
            if let Some(message) = first_choice.get("message") {
                if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                    println!("ğŸ” Detailed analysis:");
                    println!("{}", content);
                    
                    // Validate comprehensive analysis
                    let content_lower = content.to_lowercase();
                    let analyzes_scene = content_lower.contains("åœºæ™¯") || content_lower.contains("åœ°ç‚¹") || content_lower.contains("scene");
                    let discusses_lighting = content_lower.contains("å…‰çº¿") || content_lower.contains("å…‰") || content_lower.contains("lighting");
                    let mentions_composition = content_lower.contains("æ„å›¾") || content_lower.contains("è§†è§‰") || content_lower.contains("composition");
                    let shows_technique = content_lower.contains("æŠ€å·§") || content_lower.contains("æ‘„å½±") || content_lower.contains("æ‹æ‘„");
                    let cultural_elements = content_lower.contains("äººæ–‡") || content_lower.contains("ç¤¾ä¼š") || content_lower.contains("æ–‡åŒ–");
                    
                    println!("âœ… Comprehensive analysis validation:");
                    println!("   Analyzes scene/location: {}", analyzes_scene);
                    println!("   Discusses lighting: {}", discusses_lighting);
                    println!("   Mentions composition: {}", mentions_composition);
                    println!("   Shows technical insight: {}", shows_technique);
                    println!("   Identifies cultural elements: {}", cultural_elements);
                    println!("   Response depth: {} chars", content.len());
                }
            }
        }
    }

    println!(); // Empty line for spacing
    Ok(())
}

/// Test step-3 multimodal capabilities
async fn test_multimodal_step_3(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ­ Testing step-3 (Multimodal)");
    println!("Model: step-3 | Task: Advanced multimodal reasoning\n");

    let client = Client::new();
    
    // Use multiple images for multimodal comparison
    let image1_url = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==";
    let image2_url = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==";
    
    let request_body = json!({
        "model": "step-3",
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªå…·æœ‰å¤šæ¨¡æ€ç†è§£èƒ½åŠ›çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿç»¼åˆåˆ†æå¤šç§ç±»å‹çš„å†…å®¹ã€‚"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text", 
                        "text": "è¯·åˆ†æè¿™äº›å›¾ç‰‡çš„å†…å®¹å·®å¼‚ï¼Œæ¯”è¾ƒå®ƒä»¬çš„ç‰¹ç‚¹ï¼Œå¹¶è§£é‡Šä¸ºä»€ä¹ˆè¿™ç§å¤šæ ·æ€§åœ¨è§†è§‰å†…å®¹ä¸­å¾ˆé‡è¦ã€‚"
                    },
                    {
                        "type": "image_url",
                        "image_url": {"url": image1_url}
                    },
                    {
                        "type": "image_url",
                        "image_url": {"url": image2_url}
                    }
                ]
            }
        ],
        "max_tokens": 700,
        "temperature": 0.8
    });

    println!("ğŸ“¤ Sending multimodal analysis request...");
    println!("   Image 1: {}", image1_url);
    println!("   Image 2: {}", image2_url);
    let start_time = std::time::Instant::now();
    
    let response = client
        .post("https://api.stepfun.com/v1/chat/completions")
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&request_body)
        .send()
        .await?;

    let duration = start_time.elapsed();
    
    if !response.status().is_success() {
        let error_text = response.text().await?;
        eprintln!("âŒ Multimodal analysis failed: {}", error_text);
        return Err("Multimodal analysis failed".into());
    }

    let response_json: Value = response.json().await?;
    
    println!("ğŸ“¥ Multimodal analysis completed in {:?}", duration);
    
    if let Some(usage) = response_json.get("usage") {
        println!("ğŸ“Š Token usage for multimodal analysis:");
        println!("   Prompt tokens: {}", usage.get("prompt_tokens").unwrap_or(&json!(0)));
        println!("   Completion tokens: {}", usage.get("completion_tokens").unwrap_or(&json!(0)));
        println!("   Total tokens: {}", usage.get("total_tokens").unwrap_or(&json!(0)));
    }

    if let Some(choices) = response_json.get("choices").and_then(|c| c.as_array()) {
        if let Some(first_choice) = choices.first() {
            if let Some(message) = first_choice.get("message") {
                if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                    println!("ğŸ­ Multimodal analysis:");
                    println!("{}", content);
                    
                    // Validate multimodal reasoning
                    let content_lower = content.to_lowercase();
                    let compares_images = content_lower.contains("æ¯”è¾ƒ") || content_lower.contains("difference") || content_lower.contains("å¯¹æ¯”");
                    let identifies_diversity = content_lower.contains("å¤šæ ·") || content_lower.contains("å·®å¼‚") || content_lower.contains("ä¸åŒ");
                    let shows_reasoning = content_lower.contains("å› ä¸º") || content_lower.contains("åŸå› ") || content_lower.contains("é‡è¦");
                    let integrates_analysis = content_lower.contains("ç»¼åˆ") || content_lower.contains("æ•´ä½“") || content_lower.contains("æ€»ä½“");
                    
                    println!("âœ… Multimodal reasoning validation:");
                    println!("   Compares multiple images: {}", compares_images);
                    println!("   Identifies diversity: {}", identifies_diversity);
                    println!("   Shows reasoning: {}", shows_reasoning);
                    println!("   Integrates analysis: {}", integrates_analysis);
                    println!("   Advanced response length: {} chars", content.len());
                }
            }
        }
    }

    println!(); // Empty line for spacing
    Ok(())
}

/// Test with base64 encoded image (alternative to URL)
#[allow(dead_code)]
async fn test_with_base64_image(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ”¢ Testing with base64 encoded image");
    
    // Create a simple test image (1x1 pixel PNG in base64)
    let base64_image = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==";
    
    let client = Client::new();
    let request_body = json!({
        "model": "step-1o-turbo-vision",
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text", 
                        "text": "è¿™ä¸ªå›¾ç‰‡åŒ…å«ä»€ä¹ˆå†…å®¹ï¼Ÿ"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": format!("data:image/png;base64,{}", base64_image)
                        }
                    }
                ]
            }
        ],
        "max_tokens": 200
    });

    println!("ğŸ“¤ Sending base64 image analysis request...");
    
    let response = client
        .post("https://api.stepfun.com/v1/chat/completions")
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&request_body)
        .send()
        .await?;

    if response.status().is_success() {
        let response_json: Value = response.json().await?;
        if let Some(choices) = response_json.get("choices").and_then(|c| c.as_array()) {
            if let Some(first_choice) = choices.first() {
                if let Some(message) = first_choice.get("message") {
                    if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                        println!("ğŸ“¥ Base64 image analysis: {}", content);
                    }
                }
            }
        }
    }

    Ok(())
}