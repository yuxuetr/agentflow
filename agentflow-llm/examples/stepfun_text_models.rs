/// StepFun Text Models - Real API Test Cases
/// 
/// Tests actual text completion models with both streaming and non-streaming modes.
/// Demonstrates real requests and responses from StepFun API.
/// 
/// Usage:
/// ```bash
/// export STEP_API_KEY="your-stepfun-api-key-here"
/// cargo run --example stepfun_text_models
/// ```

use reqwest::Client;
use serde_json::{json, Value};
use std::env;
use tokio::time::{timeout, Duration};
use futures_util::StreamExt;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    env_logger::init();
    
    let api_key = env::var("STEP_API_KEY")
        .expect("STEP_API_KEY environment variable is required");

    println!("ğŸš€ StepFun Text Models - Real API Tests");
    println!("======================================\n");

    // Test different text models
    test_step_2_16k(&api_key).await?;
    test_step_1_32k_streaming(&api_key).await?;
    test_step_2_mini(&api_key).await?;
    test_step_1_256k_long_context(&api_key).await?;
    
    println!("âœ… All text model tests completed successfully!");
    Ok(())
}

/// Test step-2-16k with non-streaming request
async fn test_step_2_16k(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“ Testing step-2-16k (Non-streaming)");
    println!("Model: step-2-16k | Max tokens: 16K | Task: Code generation\n");

    let client = Client::new();
    let request_body = json!({
        "model": "step-2-16k",
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¨‹åºå‘˜ï¼Œæ“…é•¿ç¼–å†™é«˜è´¨é‡ã€æ˜“è¯»çš„ä»£ç ã€‚"
            },
            {
                "role": "user",
                "content": "ç”¨Pythonå®ç°ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•ï¼Œè¦æ±‚åŒ…å«è¯¦ç»†æ³¨é‡Šå’Œæµ‹è¯•ç”¨ä¾‹ã€‚"
            }
        ],
        "max_tokens": 1000,
        "temperature": 0.7,
        "top_p": 0.9
    });

    println!("ğŸ“¤ Sending request to step-2-16k...");
    let start_time = std::time::Instant::now();
    
    let response = client
        .post("https://api.stepfun.com/v1/chat/completions")
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&request_body)
        .send()
        .await?;

    let duration = start_time.elapsed();
    let status = response.status();
    
    if !status.is_success() {
        let error_text = response.text().await?;
        eprintln!("âŒ Request failed with status {}: {}", status, error_text);
        return Err(format!("HTTP {}", status).into());
    }

    let response_json: Value = response.json().await?;
    
    println!("ğŸ“¥ Response received in {:?}", duration);
    println!("ğŸ“Š Response details:");
    
    if let Some(usage) = response_json.get("usage") {
        println!("   Prompt tokens: {}", usage.get("prompt_tokens").unwrap_or(&json!(0)));
        println!("   Completion tokens: {}", usage.get("completion_tokens").unwrap_or(&json!(0)));
        println!("   Total tokens: {}", usage.get("total_tokens").unwrap_or(&json!(0)));
    }

    if let Some(choices) = response_json.get("choices").and_then(|c| c.as_array()) {
        if let Some(first_choice) = choices.first() {
            if let Some(message) = first_choice.get("message") {
                if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                    println!("ğŸ“ Generated code (first 500 chars):");
                    println!("{}", truncate_string(content, 500));
                    
                    // Validate response contains expected elements
                    let content_lower = content.to_lowercase();
                    let has_quicksort = content_lower.contains("å¿«é€Ÿæ’åº") || content_lower.contains("quicksort");
                    let has_function = content_lower.contains("def ");
                    let has_comments = content_lower.contains("#");
                    
                    println!("âœ… Response validation:");
                    println!("   Contains quicksort logic: {}", has_quicksort);
                    println!("   Contains function definition: {}", has_function);
                    println!("   Contains comments: {}", has_comments);
                }
            }
        }
    }

    println!(); // Empty line for spacing
    Ok(())
}

/// Test step-1-32k with streaming request
async fn test_step_1_32k_streaming(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸŒŠ Testing step-1-32k (Streaming)");
    println!("Model: step-1-32k | Max tokens: 32K | Task: Detailed explanation\n");

    let client = Client::new();
    let request_body = json!({
        "model": "step-1-32k",
        "messages": [
            {
                "role": "user",
                "content": "è¯¦ç»†è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†ï¼ŒåŒ…æ‹¬é‡å­æ¯”ç‰¹ã€å åŠ æ€ã€çº ç¼ ç°è±¡ï¼Œä»¥åŠå®ƒä¸ç»å…¸è®¡ç®—çš„ä¸»è¦åŒºåˆ«ã€‚"
            }
        ],
        "stream": true,
        "max_tokens": 800,
        "temperature": 0.8
    });

    println!("ğŸ“¤ Sending streaming request to step-1-32k...");
    let start_time = std::time::Instant::now();
    
    let response = client
        .post("https://api.stepfun.com/v1/chat/completions")
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&request_body)
        .send()
        .await?;

    if !response.status().is_success() {
        let error_text = response.text().await?;
        eprintln!("âŒ Streaming request failed: {}", error_text);
        return Err("Streaming request failed".into());
    }

    println!("ğŸ“¥ Receiving streaming response:");
    print!("   ");
    
    let mut stream = response.bytes_stream();
    let mut full_content = String::new();
    let mut chunk_count = 0;
    
    // Process streaming response with timeout
    while let Ok(Some(chunk_result)) = timeout(Duration::from_secs(30), stream.next()).await {
        match chunk_result {
            Ok(chunk) => {
                let chunk_str = String::from_utf8_lossy(&chunk);
                
                // Process each line in the chunk
                for line in chunk_str.lines() {
                    if line.starts_with("data: ") {
                        let data = &line[6..]; // Remove "data: " prefix
                        
                        if data.trim() == "[DONE]" {
                            let duration = start_time.elapsed();
                            println!("\n\nğŸ Streaming completed in {:?}", duration);
                            println!("ğŸ“Š Stream statistics:");
                            println!("   Total chunks received: {}", chunk_count);
                            println!("   Total content length: {} chars", full_content.len());
                            println!("   Average chunk size: {:.1} chars", 
                                   if chunk_count > 0 { full_content.len() as f32 / chunk_count as f32 } else { 0.0 });
                            
                            // Show content preview
                            println!("ğŸ“ Content preview (first 300 chars):");
                            println!("{}", truncate_string(&full_content, 300));
                            
                            // Validate streaming content
                            let content_lower = full_content.to_lowercase();
                            let has_quantum = content_lower.contains("é‡å­") || content_lower.contains("quantum");
                            let has_qubit = content_lower.contains("é‡å­æ¯”ç‰¹") || content_lower.contains("qubit");
                            let has_superposition = content_lower.contains("å åŠ ") || content_lower.contains("superposition");
                            
                            println!("âœ… Content validation:");
                            println!("   Contains quantum concepts: {}", has_quantum);
                            println!("   Contains qubit explanation: {}", has_qubit);
                            println!("   Contains superposition: {}", has_superposition);
                            
                            println!(); // Empty line for spacing
                            return Ok(());
                        }
                        
                        // Parse streaming JSON
                        if let Ok(json_data) = serde_json::from_str::<Value>(data) {
                            if let Some(choices) = json_data.get("choices").and_then(|c| c.as_array()) {
                                if let Some(choice) = choices.first() {
                                    if let Some(delta) = choice.get("delta") {
                                        if let Some(content) = delta.get("content").and_then(|c| c.as_str()) {
                                            print!("{}", content);
                                            full_content.push_str(content);
                                            chunk_count += 1;
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
            Err(e) => {
                eprintln!("\nâŒ Stream error: {}", e);
                break;
            }
        }
    }

    Ok(())
}

/// Test step-2-mini with simple question
async fn test_step_2_mini(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("âš¡ Testing step-2-mini (Fast model)");
    println!("Model: step-2-mini | Max tokens: 8K | Task: Quick reasoning\n");

    let client = Client::new();
    let request_body = json!({
        "model": "step-2-mini",
        "messages": [
            {
                "role": "user",
                "content": "è§£é‡Šä¸ºä»€ä¹ˆå¤©ç©ºæ˜¯è“è‰²çš„ï¼Ÿç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€å›ç­”ã€‚"
            }
        ],
        "max_tokens": 300,
        "temperature": 0.5
    });

    println!("ğŸ“¤ Sending request to step-2-mini...");
    let start_time = std::time::Instant::now();
    
    let response = client
        .post("https://api.stepfun.com/v1/chat/completions")
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&request_body)
        .send()
        .await?;

    let duration = start_time.elapsed();
    
    if !response.status().is_success() {
        let error_text = response.text().await?;
        eprintln!("âŒ Request failed: {}", error_text);
        return Err("Request failed".into());
    }

    let response_json: Value = response.json().await?;
    
    println!("ğŸ“¥ Response received in {:?} (fast!)", duration);
    
    if let Some(choices) = response_json.get("choices").and_then(|c| c.as_array()) {
        if let Some(first_choice) = choices.first() {
            if let Some(message) = first_choice.get("message") {
                if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                    println!("ğŸ“ Explanation:");
                    println!("{}", content);
                    
                    // Validate response quality
                    let content_lower = content.to_lowercase();
                    let has_light = content_lower.contains("å…‰") || content_lower.contains("light");
                    let has_scattering = content_lower.contains("æ•£å°„") || content_lower.contains("scattering");
                    let has_blue = content_lower.contains("è“") || content_lower.contains("blue");
                    
                    println!("âœ… Response validation:");
                    println!("   Mentions light: {}", has_light);
                    println!("   Explains scattering: {}", has_scattering);
                    println!("   Addresses blue color: {}", has_blue);
                    println!("   Response length: {} chars", content.len());
                }
            }
        }
    }

    println!(); // Empty line for spacing
    Ok(())
}

/// Test step-1-256k with long context
async fn test_step_1_256k_long_context(api_key: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“š Testing step-1-256k (Long context)");
    println!("Model: step-1-256k | Max tokens: 256K | Task: Document analysis\n");

    // Create a longer context to test the model's capabilities
    let long_context = r#"
    äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒè¯•å›¾ç†è§£æ™ºèƒ½çš„å®è´¨ï¼Œ
    å¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€
    è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚è‡ªä»äººå·¥æ™ºèƒ½è¯ç”Ÿä»¥æ¥ï¼Œç†è®ºå’ŒæŠ€æœ¯æ—¥ç›Šæˆç†Ÿï¼Œ
    åº”ç”¨é¢†åŸŸä¹Ÿä¸æ–­æ‰©å¤§ã€‚å¯ä»¥è®¾æƒ³ï¼Œæœªæ¥äººå·¥æ™ºèƒ½å¸¦æ¥çš„ç§‘æŠ€äº§å“ï¼Œå°†ä¼šæ˜¯äººç±»æ™ºæ…§çš„"å®¹å™¨"ã€‚
    
    æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒï¼Œæ˜¯ä½¿è®¡ç®—æœºå…·æœ‰æ™ºèƒ½çš„æ ¹æœ¬é€”å¾„ã€‚æœºå™¨å­¦ä¹ æ˜¯ä¸€é—¨å¤šé¢†åŸŸäº¤å‰å­¦ç§‘ï¼Œ
    æ¶‰åŠæ¦‚ç‡è®ºã€ç»Ÿè®¡å­¦ã€é€¼è¿‘è®ºã€å‡¸åˆ†æã€ç®—æ³•å¤æ‚åº¦ç†è®ºç­‰å¤šé—¨å­¦ç§‘ã€‚ä¸“é—¨ç ”ç©¶è®¡ç®—æœºæ€æ ·æ¨¡æ‹Ÿæˆ–å®ç°äººç±»çš„å­¦ä¹ è¡Œä¸ºï¼Œ
    ä»¥è·å–æ–°çš„çŸ¥è¯†æˆ–æŠ€èƒ½ï¼Œé‡æ–°ç»„ç»‡å·²æœ‰çš„çŸ¥è¯†ç»“æ„ä½¿ä¹‹ä¸æ–­æ”¹å–„è‡ªèº«çš„æ€§èƒ½ã€‚
    
    æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒåŸºäºäººå·¥ç¥ç»ç½‘ç»œã€‚æ·±åº¦å­¦ä¹ çš„æ¦‚å¿µç”±Hintonç­‰äººäº2006å¹´æå‡ºã€‚
    æ·±åº¦å­¦ä¹ é€šè¿‡å»ºç«‹ã€æ¨¡æ‹Ÿäººè„‘è¿›è¡Œåˆ†æå­¦ä¹ çš„ç¥ç»ç½‘ç»œï¼Œå®ƒæ¨¡ä»¿äººè„‘çš„æœºåˆ¶æ¥è§£é‡Šæ•°æ®ï¼Œä¾‹å¦‚å›¾åƒã€å£°éŸ³å’Œæ–‡æœ¬ã€‚
    "#.repeat(3); // Repeat to create longer context

    let client = Client::new();
    let request_body = json!({
        "model": "step-1-256k",
        "messages": [
            {
                "role": "system",
                "content": format!("ä½ æ˜¯ä¸€ä¸ªAIä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š\n\n{}", long_context)
            },
            {
                "role": "user",
                "content": "æ ¹æ®ä¸Šè¿°æ–‡æ¡£ï¼Œæ€»ç»“äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶è§£é‡Šå®ƒä»¬çš„å‘å±•è„‰ç»œã€‚"
            }
        ],
        "max_tokens": 600,
        "temperature": 0.7
    });

    println!("ğŸ“¤ Sending long context request to step-1-256k...");
    println!("   Context length: {} chars", long_context.len());
    let start_time = std::time::Instant::now();
    
    let response = client
        .post("https://api.stepfun.com/v1/chat/completions")
        .header("Content-Type", "application/json")
        .header("Authorization", format!("Bearer {}", api_key))
        .json(&request_body)
        .send()
        .await?;

    let duration = start_time.elapsed();
    
    if !response.status().is_success() {
        let error_text = response.text().await?;
        eprintln!("âŒ Long context request failed: {}", error_text);
        return Err("Request failed".into());
    }

    let response_json: Value = response.json().await?;
    
    println!("ğŸ“¥ Long context response received in {:?}", duration);
    
    if let Some(usage) = response_json.get("usage") {
        println!("ğŸ“Š Token usage for long context:");
        println!("   Prompt tokens: {}", usage.get("prompt_tokens").unwrap_or(&json!(0)));
        println!("   Completion tokens: {}", usage.get("completion_tokens").unwrap_or(&json!(0)));
        println!("   Total tokens: {}", usage.get("total_tokens").unwrap_or(&json!(0)));
    }

    if let Some(choices) = response_json.get("choices").and_then(|c| c.as_array()) {
        if let Some(first_choice) = choices.first() {
            if let Some(message) = first_choice.get("message") {
                if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                    println!("ğŸ“ Long context analysis:");
                    println!("{}", content);
                    
                    // Validate long context understanding
                    let content_lower = content.to_lowercase();
                    let mentions_ai = content_lower.contains("äººå·¥æ™ºèƒ½") || content_lower.contains("ai");
                    let mentions_ml = content_lower.contains("æœºå™¨å­¦ä¹ ");
                    let mentions_dl = content_lower.contains("æ·±åº¦å­¦ä¹ ");
                    let shows_relationship = content_lower.contains("å…³ç³»") || content_lower.contains("åˆ†æ”¯");
                    
                    println!("âœ… Long context validation:");
                    println!("   Mentions AI: {}", mentions_ai);
                    println!("   Mentions ML: {}", mentions_ml);
                    println!("   Mentions DL: {}", mentions_dl);
                    println!("   Shows relationships: {}", shows_relationship);
                }
            }
        }
    }

    println!(); // Empty line for spacing
    Ok(())
}

/// Utility function to truncate strings for display (Unicode-safe)
fn truncate_string(s: &str, max_len: usize) -> String {
    if s.chars().count() <= max_len {
        s.to_string()
    } else {
        let truncated: String = s.chars().take(max_len).collect();
        format!("{}...\n[Truncated - showing first {} of {} characters]", 
                truncated, max_len, s.chars().count())
    }
}